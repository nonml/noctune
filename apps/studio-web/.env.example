# --- Noctune Studio (local-first) ---
#
# OpenAI-compatible endpoint (llama.cpp server)
NOCTUNE_STUDIO_LLM_BASE_URL=http://127.0.0.1:8080/v1
NOCTUNE_STUDIO_LLM_API_KEY=local
NOCTUNE_STUDIO_LLM_MODEL=
#
# Allow the Studio UI to operate on repos under these roots (comma-separated).
# If unset, it defaults to the monorepo root (../.. from this web app).
NOCTUNE_STUDIO_ALLOWED_ROOTS=
NOCTUNE_STUDIO_DEFAULT_REPO_ROOT=
#
# Python executable used to spawn `python -m noctune ...` from the web app
NOCTUNE_STUDIO_PYTHON=python3

